---
---
@inproceedings{liu2026doki,
  title        = {A Text-Native Interface for Generative Video Authoring},
  author       = {Xingyu Bruce Liu and Mira Dontcheva and Dingzeyu Li},
  booktitle    = {Submission},
  year         = {2026},
  series       = {Under Review},

  selected={true},
  preview={liu2026doki.png},
}


@inproceedings{liu2025uistdc,
  title        = {Thought as a Substrate in Human-AI Interaction},
  author       = {Xingyu Bruce Liu},
  booktitle    = {UIST 2025 Doctoral Symposium},
  year         = {2025},
  publisher    = {ACM},
  series       = {UIST '25},

  abbr={UIST},
  selected={true},
  preview={liu2025interacting.png},
  pdf={liu2025uistdc.pdf},
  url={https://dl.acm.org/doi/10.1145/3746058.3758466},
}

@inproceedings{liu2025interacting,
  title        = {Interacting with Thoughtful AI},
  author       = {Xingyu Bruce Liu and Haijun Xia and Xiang Anthony Chen},
  booktitle    = {CHI 2025 Workshop on Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI},
  year         = {2025},
  publisher    = {ACM},
  series       = {CHI '25},
  arxiv        = {2502.18676},

  abbr={CHI},
  preview={liu2025interacting.png},
  pdf={liu2025interacting.pdf},
}


@inproceedings{liu2025inner,
  title={{Proactive Conversational Agents with Inner Thoughts}},
  author={Liu, Xingyu Bruce and Fang, Shitao and Shi, Weiyan and Wu, Chien-Sheng and Igarashi, Takeo and Chen, Xiang Anthony},
  booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  year = {2025},
  publisher = {ACM},
  series = {CHI '25},
  keywords = {Full},

  doi = {10.1145/3706598.3713760},
  url={https://doi.org/10.1145/3706598.3713760},
  arxiv={2501.00383},
  abbr={CHI},
  selected={true},
  preview={liu2025inner.png},
  pdf={liu2025inner.pdf},
  code={https://github.com/xybruceliu/thoughtful-agents},
  website={https://liubruce.me/inner_thoughts/},
}


@inproceedings{liu2024humanio,
  title={{Human I/O: Towards a Unified Approach to Detecting Situational Impairments}},
  author={Liu, Xingyu Bruce and Li, Jiaohao Nick and Kim, David and Chen, Xiang Anthony and Du, Ruofei},
  booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  year = {2024},
  publisher = {ACM},
  series = {CHI '24},
  keywords = {Full},
  doi = {10.1145/3613904.3642065},
  url={https://doi.org/10.1145/3613904.3642065},

  abbr={CHI},
  award={Honorable Mention},
  selected={true},
  preview={liu2024humanio.png},
  blog={https://research.google/blog/human-io-detecting-situational-impairments-with-large-language-models/},
  pdf={liu2024humanio.pdf},
  website={https://liubruce.me/human_io/},
}


@inproceedings{liu2023vcdemo,
  author = {Liu, Xingyu Bruce and Kirilyuk, Vladimir and Yuan, Xiuxiu and Chi, Peggy and Olwal, Alex and Chen, Xiang Anthony and Du, Ruofei},
  title = {Experiencing Visual Captions: Augmented Communication with Real-Time Visuals Using Large Language Models},
  year = {2023},
  isbn = {9798400700965},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3586182.3615978},
  doi = {10.1145/3586182.3615978},
  booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {85},
  numpages = {4},
  keywords = {dataset, text-to-visual, augmented reality, augmented communication, online meeting, collaborative work, video-mediated communication, large language models, AI agent},
  location = {San Francisco, CA, USA},
  series = {UIST '23 Adjunct},

  abbr={UIST},
  preview={liu2023vcdemo.png},
}


@article{liu2023social,
  author = {Liu*, Xingyu Bruce and Leong*, Joanne and Teng*, Yuanyang and Jun, Hanseul and Kratz, Sven and Tham, Yu Jiang and Monroy-Hern\'{a}ndez, Andr\'{e}s and Smith, Brian A. and Vaish, Rajan},
  title = {Social Wormholes: Exploring Preferences and Opportunities for Distributed and Physically-Grounded Social Connections},
  year = {2023},
  issue_date = {October 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {7},
  number = {CSCW2},
  series = {CSCW '23},
  url = {https://doi.org/10.1145/3610208},
  doi = {10.1145/3610208},
  journal = {Proc. ACM Hum.-Comput. Interact.},
  month = {oct},
  articleno = {359},
  numpages = {29},
  keywords = {smart glasses, augmented reality, social connection, ubiquitous computing},


  abbr={CSCW},
  preview={liu2023social.png},
}

@inproceedings{liu2023visualcaptions,
  author = {Liu, Xingyu Bruce and Kirilyuk, Vladimir and Yuan, Xiuxiu and Olwal, Alex and Chi, Peggy and Chen, Xiang Anthony and Du, Ruofei},
  title = {Visual Captions: Augmenting Verbal Communication with On-the-fly Visuals},
  year = {2023},
  isbn = {},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581566},
  doi = {},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  keywords = {Computer Mediated Communication ; Artifact or System ; Dataset ; Empirical study that tells us about how people use a system},
  location = {Hamburg, Germany},
  series = {CHI '23},

  abbr={CHI},
  pdf={liu2023visual.pdf},
  video={https://youtu.be/sL_YeHtQt44},
  blog={https://blog.research.google/2023/06/visual-captions-using-large-language.html},
  website={https://liubruce.me/visual_captions/},
  code={https://github.com/google/archat},
  selected={true},
  preview={liu2023visualcaptions.png},
}

@inproceedings{Du2023Rapsai,
  title = {{Rapsai: Accelerating Machine Learning Prototyping of Multimedia Applications Through Visual Programming}},
  author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Miles, Scott and Kleiner, Maria and Yuan, Xiuxiu and Zhang, Yinda and Kulkarni, Anuva and Liu, Xingyu Bruce and Escolano, Sergio and Kar, Abhishek and Olwal, Alex and Yu, Ping and Iyengar, Ram and Kowdle, Adarsh},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  year = {2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {CHI '23},
  url={https://dl.acm.org/doi/10.1145/3544548.3581338},

  award={Honorable Mention},
  abbr={CHI},
  pdf={du2023rapsai.pdf},
  video={https://youtu.be/mQ5mvAbZYvc},
  preview={du2023rapsai.png},
}


@inproceedings{Liu2023Modeling,
  title = {{Modeling and Improving Text Stability in Live Captions}},
  author = {Liu, Xingyu Bruce and Zhang, Jun and Ferrer, Leonardo and Xu, Susan and Bahirwani, Vikas and Smus, Boris and Olwal, Alex and Du, Ruofei},
  booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
  year = {2023},
  publisher = {ACM},
  series = {CHI EA '23},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544549.3585609},
  url={https://doi.org/10.1145/3544549.3585609},

  abbr={CHI},
  pdf={liu2023modeling.pdf},
  video={https://youtu.be/Indi_RwODS8},
  preview={Liu2023Modeling.png},
}




@inproceedings{liu2022crossa11y, 
author = {Liu, Xingyu Bruce and Wang, Ruolin and Li, Dingzeyu and Chen, Xiang Anthony and Pavel, Amy},
title = {CrossA11y: Identifying Video Accessibility Issues via Cross-Modal Grounding},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3526113.3545703},
url={https://doi.org/10.1145/3526113.3545703},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {43},
numpages = {14},
keywords = {audio description, video, accessibility, closed caption},
location = {Bend, OR, USA},
series = {UIST '22},

abbr={UIST},
award={Best Paper Award},
pdf={liu2022crossa11y.pdf},
video={https://youtu.be/HDqjnHOZ7J8},
website={https://liubruce.me/CrossA11y/},
selected={true},
preview={liu2022crossa11y.png},
}


@inproceedings{liu2021what,
author = {Liu, Xingyu and Carrington, Patrick and Chen, Xiang Anthony and Pavel, Amy},
title = {What Makes Videos Accessible to Blind and Visually Impaired People?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445233},
doi = {10.1145/3411764.3445233},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {272},
numpages = {14},
keywords = {visual impairments, blind, online videos, accessibility},
location = {Yokohama, Japan},
series = {CHI '21},

abbr={CHI},
pdf={liu2021what.pdf},
video={https://youtu.be/n2enrJJZdTs},
selected={true},
preview={liu2021what.png},
}


@inproceedings{gleason2019making,
author = {Gleason, Cole and Pavel, Amy and Liu, Xingyu and Carrington, Patrick and Chilton, Lydia B. and Bigham, Jeffrey P.},
title = {Making Memes Accessible},
year = {2019},
isbn = {9781450366762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308561.3353792},
doi = {10.1145/3308561.3353792},
booktitle = {Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {367â€“376},
numpages = {10},
keywords = {blind, social media, audio, image description, alternative text, meme, low vision},
location = {Pittsburgh, PA, USA},
series = {ASSETS '19},

abbr={ASSETS},
pdf={gleason2019making.pdf},
blog={https://time.com/5759721/meme-accessibility-blind/},
website={https://dl.acm.org/doi/10.1145/3308561.3353792},
preview={gleason2019making.png},
}