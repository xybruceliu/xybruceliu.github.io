---
layout: about
title: about
permalink: /
subtitle: "åˆ˜æ˜Ÿå®‡"


profile:
  align: right
  image: prof_pic_2.jpg
  image_circular: false # crops the image to make it circular
  address: 
    <p>ğŸ“§ <a href=mailto:xingyuliu@ucla.edu?subject="HTML link">xingyuliu@ucla.edu</a></p>
    <p>ğŸ¦ <a href=https://twitter.com/liu_xingyu>@liu_xingyu</a></p>
    <p><a target="_blank" href=https://www.semanticscholar.org/author/Xingyu-Bruce-Liu/2146036493>Semantic Scholar</a></p>
    <p><a target="_blank" href=https://scholar.google.com/citations?user=CTDSuK0AAAAJ>Google Scholar</a></p>
    <p><a target="_blank" href=assets/pdf/bruceliu_cv.pdf>Curriculum vitae</a></p>
news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

Greetings! I'm Bruce, a Ph.D. student at the [UCLA HCI lab](https://hci.ucla.edu/) advised by Professor [Xiang 'Anthony' Chen](https://hci.prof/).


I focus on HCI+AI research, exploring the <b>future forms of LLMs and AI agents</b> beyond a turn-based chatbot. 


Examples include: agents that can proactively engage in group conversations by modeling human-like motivations ([Inner Thoughts](https://liubruce.me/inner_thoughts/)), multimodal agents that stay in sync with real-world context ([Human I/O](https://research.google/blog/human-io-detecting-situational-impairments-with-large-language-models/)), real-time AI that dynamically generates visuals to complement speech ([Visual Captions](https://research.google/blog/visual-captions-using-large-language-models-to-augment-video-conferences-with-dynamic-visuals/)), and a document interface that lets anyone author generative videos by simply writing ([Doki](https://liubruce.me/doki/)).


My work has been recognized and supported by an [Amazon Ph.D. Fellowship](https://www.sciencehub.ucla.edu/2023-amazon-fellows/), an [ACM UIST Best Paper Award ğŸ†](https://programs.sigchi.org/uist/2022/awards/best-papers), two [ACM CHI Best Paper Honorable Mentions ğŸ…](https://programs.sigchi.org/chi/2024/program/content/148270). I also did research internships at [Adobe Research](https://research.adobe.com/), [Google](https://research.google/), [Meta Reality Labs](https://about.meta.com/realitylabs/) and [Snap Research](https://www.snap.com/en-US).